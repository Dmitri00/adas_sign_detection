{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmitri00/adas_sign_detection/blob/master/sign_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq35mzKM74Hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvf rtsd-r1.tar > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlKxnhNqRbfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f88ea81-c3a1-4b91-b38f-bb23e6b34219"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwV0as_y7-mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "import skimage.filters as filters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import os.path\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "%matplotlib inline\n",
        "def laplace_stats(img):\n",
        "  im_gray = rgb2gray(im)\n",
        "  im_laplace = filters.laplace(im_gray, 3)\n",
        "  return np.mean(im_laplace), np.std(im_laplace)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aAV-EAe-7T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Huawei/datasets/rtsd/rtsd-r1'\n",
        "data_dir_test = '/content/drive/My Drive/Huawei/datasets/rtsd/rtsd-r1/test'\n",
        "data_dir_train = '/content/drive/My Drive/Huawei/datasets/rtsd/rtsd-r1/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx4XkQmZ_H_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d99ce2dc-2243-4be8-fef0-ba5b28e8f62c"
      },
      "source": [
        "img_list_train = list(map( lambda x: os.path.join(data_dir_train, x), os.listdir(data_dir_train)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-035e5fb7b361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_list_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/Huawei/datasets/rtsd/rtsd-r1/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gHKPUyR_YyH",
        "colab_type": "code",
        "outputId": "82b7e293-8b2e-4879-8b6e-4acdfef629f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "i = 13\n",
        "im = imread(img_list_train[i])\n",
        "fig, axes = plt.subplots(2,2)\n",
        "\n",
        "axes[0,0].imshow(im)\n",
        "im_gray = rgb2gray(im)\n",
        "im_laplace = filters.laplace(im_gray, 3)\n",
        "\n",
        "bins, nums = np.histogram(im_laplace)\n",
        "#im_laplace = np.abs(im_laplace)\n",
        "print('{:.5f} +- {:.3f}'.format(np.mean(im_laplace), 3*np.std(im_laplace) ))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9d27734c0e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_list_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qva_IS2zAVpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c610f5fd-3ed5-4b8e-946a-2b4e9cacc01d"
      },
      "source": [
        "\n",
        "\n",
        "num_instances = 10\n",
        "is_blurred = np.zeros(num_instances)\n",
        "mean_std = np.zeros((num_instances, 2))\n",
        "fig = plt.figure()\n",
        "for i, im in tqdm(enumerate(img_list_train[:num_instances])):\n",
        "  \n",
        "  im = imread(im)\n",
        "  plt.imshow(im)\n",
        "  plt.show()\n",
        "  \n",
        "  input()\n",
        "  #is_blurred[i] = img_is_blurred\n",
        "  mean_col = 0\n",
        "  std_col = 1\n",
        "  mean, std = laplace_stats(im)\n",
        "  #print(clf.predict([[mean, std]])[0])\n",
        "  print(blur_predictor(torch.Tensor(im)))\n",
        "  plt.clf()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2d0c4d4d5dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmean_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_list_train' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wUGoUcZCcli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_scatter(X, y):\n",
        "  X_blurred = X[y == 1]\n",
        "  X_not_blurred = X[y == 0]\n",
        "  plt.scatter(X_blurred[:,0],X_blurred[:,1], c='b')\n",
        "  plt.scatter(X_not_blurred[:,0], X_not_blurred[:,1], c='r')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPz9IDPbT1LV",
        "colab_type": "code",
        "outputId": "7bd95d17-6fcc-4dbd-ac9d-a3665965356e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0, C=np.inf)\n",
        "clf.coef_ = np.array([[352.95659389, -38.69546198]])\n",
        "clf.intercept_ = np.array([4.55069124])\n",
        "clf.classes_ = np.array([0, 1])\n",
        "draw_scatter(mean_std, clf.predict(mean_std))\n",
        "mean_coef, std_coef = clf.coef_[0]\n",
        "bias = clf.intercept_\n",
        "mean = np.linspace(mean_std[:,0].min(), mean_std[:,0].max())\n",
        "std = - (mean * mean_coef + bias) / std_coef\n",
        "plt.plot(mean,std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f70dd1353c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hwZQmdMN1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class BlurancePredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(2,1)\n",
        "    self.fc.load_state_dict({'weight': torch.Tensor([[352.95659389, -38.69546198]]),\n",
        "                              'bias': torch. Tensor([4.55069124])})\n",
        "  def __call__(self, img):\n",
        "    mean, std = laplace_stats(img)\n",
        "    x = torch.Tensor([mean, std])\n",
        "    return F.sigmoid(self.fc(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HzDcDQKF244",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blur_predictor = BlurancePredictor()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSbOvZFnMYfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "class TrafficSign(object):\n",
        "    def __init__(self, root, image_set, transforms):\n",
        "        if image_set == 'train':\n",
        "            self.root = os.path.join(root, 'test')\n",
        "            self.gt_name = os.path.join(root, \"gt_train.csv\")\n",
        "        elif image_set == 'val' or image_set == 'test':\n",
        "            self.root = os.path.join(root, 'test') \n",
        "            self.gt_name = os.path.join(root, \"gt_test.csv\")\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to\n",
        "        # ensure that they are aligned\n",
        "        files_in_dir = os.listdir(self.root)\n",
        "        self.imgs = sorted(files_in_dir)\n",
        "        with open(self.gt_name, 'r') as gt_file:\n",
        "            gt_lines = gt_file.readlines()\n",
        "        self.ground_truth = self.parse_ground_truth(gt_lines[1:])\n",
        "    def parse_ground_truth(self, gt_lines):\n",
        "        class_set = set()\n",
        "        ground_truth = []\n",
        "        for entry_line in gt_lines:\n",
        "            entry_splited = entry_line.split(',')\n",
        "            img_name = entry_splited[0]\n",
        "            class_ = int(entry_splited[1])\n",
        "            if class_ not in class_set:\n",
        "              class_set.add(class_)\n",
        "            ground_truth.append(class_)\n",
        "        self.classes = sorted(list(class_set))\n",
        "        return ground_truth\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        img_name = self.imgs[idx]\n",
        "        img_path = os.path.join(self.root, img_name)\n",
        "        label = self.ground_truth[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # there is only one class\n",
        "        label = torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4WNZnauNsXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "#data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: TrafficSign(data_dir, x, data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "NUM_CLASSES = len(image_datasets['train'].classes)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGcybC-EN4m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.intrinsic as inn\n",
        "import torch.quantization as quant\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        # input 3x48x48\n",
        "        self.quant = quant.QuantStub()\n",
        "        \n",
        "        self.conv1 = inn.ConvReLU2d(nn.Conv2d(3, 6, 5), nn.ReLU())\n",
        "        # 6x44x44\n",
        "        self.conv2 = inn.ConvReLU2d(nn.Conv2d(6, 6, 3, padding=1, stride=2), nn.ReLU())\n",
        "        # 6x22x22\n",
        "        self.conv3 = inn.ConvReLU2d(nn.Conv2d(6, 16, 5), nn.ReLU())\n",
        "        # 16x18x18\n",
        "        self.conv4 = inn.ConvReLU2d(nn.Conv2d(16, 16, 3, padding=1, stride=2), nn.ReLU())\n",
        "        # 16x9x9\n",
        "        self.flat_features_len = 16 * 9 * 9\n",
        "        self.fc1 = inn.LinearReLU(nn.Linear(self.flat_features_len, 120), nn.ReLU())\n",
        "        self.fc2 = inn.LinearReLU(nn.Linear(120, 84), nn.ReLU())\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.dequant = quant.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = x.view(-1, self.flat_features_len)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net(NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1j1Dh88OABI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "device = torch.device('cuda')\n",
        "net = net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQw3mOPCiu5u",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMT4MpbPX4NF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91559f3b-af65-4306-9cab-b03dbcdf11d9"
      },
      "source": [
        "!git clone https://github.com/pytorch/vision.git"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'vision' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3KMl9c1X6ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp vision/references/classification/* ./\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPDXEBPfhDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from train import train_one_epoch, evaluate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoiJy-WGimeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "44548c84-e327-4794-9a7c-ab51d27f8830"
      },
      "source": [
        "train_one_epoch(net, criterion, \n",
        "                optimizer, dataloaders['train'], \n",
        "                device, 0, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [  0/472]  eta: 1:02:52  lr: 0.001  img/s: 2089.252015815199  loss: 4.2007 (4.2007)  acc1: 0.0000 (0.0000)  acc5: 12.5000 (12.5000)  time: 7.9928  data: 7.9851  max mem: 8\n",
            "Epoch: [0]  [ 10/472]  eta: 0:25:21  lr: 0.001  img/s: 4657.750138811772  loss: 4.1892 (4.1884)  acc1: 0.0000 (2.2727)  acc5: 18.7500 (17.6136)  time: 3.2927  data: 3.2885  max mem: 8\n",
            "Epoch: [0]  [ 20/472]  eta: 0:23:15  lr: 0.001  img/s: 3839.838873948618  loss: 4.1847 (4.1859)  acc1: 6.2500 (6.5476)  acc5: 18.7500 (16.6667)  time: 2.8414  data: 2.8375  max mem: 8\n",
            "Epoch: [0]  [ 30/472]  eta: 0:20:14  lr: 0.001  img/s: 5465.336265168174  loss: 4.1858 (4.1867)  acc1: 6.2500 (6.8548)  acc5: 12.5000 (14.5161)  time: 2.4494  data: 2.4459  max mem: 8\n",
            "Epoch: [0]  [ 40/472]  eta: 0:19:57  lr: 0.001  img/s: 4059.3312363900313  loss: 4.1837 (4.1846)  acc1: 6.2500 (8.6890)  acc5: 12.5000 (14.7866)  time: 2.4427  data: 2.4394  max mem: 8\n",
            "Epoch: [0]  [ 50/472]  eta: 0:18:58  lr: 0.001  img/s: 4397.121216092255  loss: 4.1815 (4.1846)  acc1: 6.2500 (8.3333)  acc5: 12.5000 (13.8480)  time: 2.6218  data: 2.6183  max mem: 8\n",
            "Epoch: [0]  [ 60/472]  eta: 0:18:39  lr: 0.001  img/s: 4580.1845481845485  loss: 4.1753 (4.1822)  acc1: 6.2500 (8.9139)  acc5: 12.5000 (14.4467)  time: 2.6068  data: 2.6030  max mem: 8\n",
            "Epoch: [0]  [ 70/472]  eta: 0:18:05  lr: 0.001  img/s: 5823.90558014406  loss: 4.1720 (4.1816)  acc1: 6.2500 (8.8028)  acc5: 12.5000 (13.9965)  time: 2.7056  data: 2.7021  max mem: 8\n",
            "Epoch: [0]  [ 80/472]  eta: 0:17:54  lr: 0.001  img/s: 3865.9406647848377  loss: 4.1636 (4.1784)  acc1: 12.5000 (9.4907)  acc5: 18.7500 (15.5093)  time: 2.8093  data: 2.8058  max mem: 8\n",
            "Epoch: [0]  [ 90/472]  eta: 0:16:48  lr: 0.001  img/s: 6039.314614830813  loss: 4.1601 (4.1767)  acc1: 12.5000 (10.0275)  acc5: 18.7500 (15.9341)  time: 2.4277  data: 2.4240  max mem: 8\n",
            "Epoch: [0]  [100/472]  eta: 0:17:10  lr: 0.001  img/s: 4854.518518518518  loss: 4.1575 (4.1742)  acc1: 12.5000 (10.3960)  acc5: 18.7500 (16.5223)  time: 2.8960  data: 2.8927  max mem: 8\n",
            "Epoch: [0]  [110/472]  eta: 0:16:19  lr: 0.001  img/s: 4661.9565126780135  loss: 4.1462 (4.1721)  acc1: 12.5000 (10.6982)  acc5: 25.0000 (17.1171)  time: 3.0068  data: 3.0032  max mem: 8\n",
            "Epoch: [0]  [120/472]  eta: 0:16:05  lr: 0.001  img/s: 4993.962196755469  loss: 4.1465 (4.1707)  acc1: 12.5000 (10.7438)  acc5: 18.7500 (17.0971)  time: 2.5907  data: 2.5868  max mem: 8\n",
            "Epoch: [0]  [130/472]  eta: 0:15:38  lr: 0.001  img/s: 5707.506718829733  loss: 4.1507 (4.1684)  acc1: 6.2500 (10.7824)  acc5: 12.5000 (17.1756)  time: 2.9583  data: 2.9543  max mem: 8\n",
            "Epoch: [0]  [140/472]  eta: 0:15:22  lr: 0.001  img/s: 4006.260163572324  loss: 4.1438 (4.1666)  acc1: 6.2500 (10.6383)  acc5: 12.5000 (17.1099)  time: 2.9947  data: 2.9910  max mem: 8\n",
            "Epoch: [0]  [150/472]  eta: 0:14:37  lr: 0.001  img/s: 4463.806305707064  loss: 4.1479 (4.1663)  acc1: 6.2500 (10.4305)  acc5: 12.5000 (16.9702)  time: 2.5901  data: 2.5866  max mem: 8\n",
            "Epoch: [0]  [160/472]  eta: 0:14:17  lr: 0.001  img/s: 2980.2319921840303  loss: 4.1544 (4.1648)  acc1: 6.2500 (10.2484)  acc5: 18.7500 (17.1972)  time: 2.5393  data: 2.5355  max mem: 8\n",
            "Epoch: [0]  [170/472]  eta: 0:13:35  lr: 0.001  img/s: 5977.985391056476  loss: 4.1523 (4.1641)  acc1: 6.2500 (9.9781)  acc5: 18.7500 (17.2149)  time: 2.5288  data: 2.5251  max mem: 8\n",
            "Epoch: [0]  [180/472]  eta: 0:13:11  lr: 0.001  img/s: 3973.054526078977  loss: 4.1321 (4.1612)  acc1: 12.5000 (10.4627)  acc5: 25.0000 (18.0594)  time: 2.4201  data: 2.4165  max mem: 8\n",
            "Epoch: [0]  [190/472]  eta: 0:12:38  lr: 0.001  img/s: 4853.816288152756  loss: 4.1321 (4.1596)  acc1: 18.7500 (10.4385)  acc5: 31.2500 (18.6191)  time: 2.5789  data: 2.5752  max mem: 8\n",
            "Epoch: [0]  [200/472]  eta: 0:12:11  lr: 0.001  img/s: 4665.8460682750465  loss: 4.1332 (4.1574)  acc1: 12.5000 (10.5410)  acc5: 31.2500 (19.5896)  time: 2.4836  data: 2.4801  max mem: 8\n",
            "Epoch: [0]  [210/472]  eta: 0:11:45  lr: 0.001  img/s: 4855.572245134216  loss: 4.1194 (4.1555)  acc1: 12.5000 (10.7227)  acc5: 31.2500 (19.9645)  time: 2.7107  data: 2.7071  max mem: 8\n",
            "Epoch: [0]  [220/472]  eta: 0:11:14  lr: 0.001  img/s: 3967.8864778572697  loss: 4.1191 (4.1538)  acc1: 12.5000 (10.7466)  acc5: 31.2500 (20.7014)  time: 2.5525  data: 2.5490  max mem: 8\n",
            "Epoch: [0]  [230/472]  eta: 0:10:49  lr: 0.001  img/s: 4888.822320973264  loss: 4.1142 (4.1521)  acc1: 12.5000 (10.7143)  acc5: 37.5000 (21.3745)  time: 2.5996  data: 2.5962  max mem: 8\n",
            "Epoch: [0]  [240/472]  eta: 0:10:14  lr: 0.001  img/s: 4215.645706388592  loss: 4.1142 (4.1507)  acc1: 6.2500 (10.6587)  acc5: 37.5000 (21.9139)  time: 2.3616  data: 2.3580  max mem: 8\n",
            "Epoch: [0]  [250/472]  eta: 0:09:49  lr: 0.001  img/s: 4612.927137750894  loss: 4.1045 (4.1491)  acc1: 6.2500 (10.5080)  acc5: 37.5000 (22.6096)  time: 2.3218  data: 2.3181  max mem: 8\n",
            "Epoch: [0]  [260/472]  eta: 0:09:22  lr: 0.001  img/s: 4109.04139113397  loss: 4.0911 (4.1464)  acc1: 6.2500 (10.6561)  acc5: 43.7500 (23.4435)  time: 2.6695  data: 2.6659  max mem: 8\n",
            "Epoch: [0]  [270/472]  eta: 0:08:59  lr: 0.001  img/s: 4872.494300442895  loss: 4.0848 (4.1438)  acc1: 12.5000 (10.7242)  acc5: 43.7500 (24.1236)  time: 2.8587  data: 2.8550  max mem: 8\n",
            "Epoch: [0]  [280/472]  eta: 0:08:31  lr: 0.001  img/s: 5398.074646074646  loss: 4.0865 (4.1417)  acc1: 6.2500 (10.6984)  acc5: 43.7500 (24.7109)  time: 2.7942  data: 2.7905  max mem: 8\n",
            "Epoch: [0]  [290/472]  eta: 0:08:03  lr: 0.001  img/s: 5061.382004676069  loss: 4.0851 (4.1395)  acc1: 12.5000 (10.7818)  acc5: 43.7500 (25.3007)  time: 2.5243  data: 2.5208  max mem: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgzGjypujB_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}